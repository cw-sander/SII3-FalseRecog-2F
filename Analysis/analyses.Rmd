---
title: "Analyses for SII Experiment 5"
output: 
  html_notebook:
  code_folding: hide
---

```{r setup, include=FALSE}
# R version 4.2.1
# load packages & set options
library(dplyr) # dplyr_1.0.10
library(ggdist) # ggdist_3.2.0
library(ggplot2) # ggplot2_3.3.6
library(ggpubr) # ggpubr_0.4.0
library(ggrepel, include.only = "geom_label_repel") # ggrepel_0.9.1
library(here) # here_1.0.1
library(lmerTest) # lmerTest_3.1-3
library(magrittr, include.only = "%T>%") # magrittr_2.0.3
library(rstatix) # rstatix_0.7.0
library(showtext) # showtext_0.9-5
library(tidyverse) # tidyverse_1.3.2

# Read data
d_long <- readRDS(here::here("Processed data/d-long.rds"))

# Demographics
dems <- d_long %>%
  select(subject_id, age, gender, starts_with("pol_")) %>%
  unique()

# Add custom font for plots
font_add("Nunito",
  regular = "/Users/carsten/Library/Fonts/NunitoSans-Regular.ttf",
  italic = "/Users/carsten/Library/Fonts/NunitoSans-Italic.ttf",
  bold = "/Users/carsten/Library/Fonts/NunitoSans-Bold.ttf",
  bolditalic = "/Users/carsten/Library/Fonts/NunitoSans-BoldItalic.ttf")
font_add("Calibri",
  regular = "/Users/carsten/Library/Fonts/Calibri.ttf",
  italic = "/Users/carsten/Library/Fonts/Calibrii.ttf",
  bold = "/Users/carsten/Library/Fonts/Calibrib.ttf",
  bolditalic = "/Users/carsten/Library/Fonts/Calibriz.ttf")
showtext_auto()

# Custom functions
formp <- function(p, text = FALSE) {
  ## ---------------------------
  ## Format p values
  ##
  ## This function takes in a number between
  ## zero and one or a formatted p-value and outputs
  ## a formatted p-value. If p-value is already formatted
  ## then applying the function changes the format from
  ## "p = .034" to ".034" and vice versa.
  ##
  ## @p p-value to be formatted
  ## @text adds "p = " or "p < " to output
  ##
  ## @out string with formatted p-value
  ## ---------------------------

  # If already formatted but no "p" then add "p"
  if (grepl("^<.\\d{3}$", p)) {
  out <- gsub("<", "p < ", p)
  } else if (grepl("^.\\d{3}$", p)) {
  out <- gsub("^", "p = ", p)
  # If already formatted and "p" then remove "p"
  } else if (grepl("^p < .\\d{3}$", p)) {
  out <- gsub("p < ", "<", p)
  } else if (grepl("^p = .\\d{3}$", p)) {
  out <- gsub("p = ", "", p)
  # If not yet formatted and smaller than .001
  } else if (is.numeric(p) && p < 0.001) {
  if (text) {
    out <- "p < .001"
  } else {
    out <- "<.001"
  }
  # If not yet formatted and bigger than .001
  } else if (p >= 0.001) {
  p <- format(round(p, 3), nsmall = 3, scientific = FALSE)
  p <- sub("0.", ".", p)
  if (text) {
    out <- paste("p =", p)
  } else {
    out <- p
  }
  }
  return(out)
}
forma <- function(number, dec = NULL, lead_zero = TRUE) { # nolint
  ## ---------------------------
  ## Format values in apa style
  ##
  ## This function takes in a number and outputs
  ## a formatted number. If no decimal is provided, then
  ## it uses a heuristic to round the number. If lead_zero
  ## is set to FALSE, then the lead zero of the number is
  ## removed (useful for p-values or eta squared).
  ##
  ## @number input number
  ## @dec optional number of decimals
  ## @lead_zero keep leading zero
  ##
  ## @out formatted number
  ## ---------------------------

  # If dec is logical, interpret as lead_zero
  if (is.logical(dec)) {
  lead_zero <- dec
  dec <- NULL
  }
  # If no decimal is specified, use heuristic
  if (!is.null(dec)) {
  } else if (abs(number) >= 100) {
  dec <- 0
  } else if (abs(number) >= 10 && number < 100) {
  dec <- 1
  } else if (abs(number) >= 0.1 && number < 10) {
  dec <- 2
  } else if (abs(number) >= 0.001 && number < 0.1) {
  dec <- 3
  } else if (abs(number) < 0.001 && number != 0) {
  dec <- stringr::str_locate(format(
    abs(number), scientific = FALSE), "[1-9]{1}")[1] - 2
  } else if (number == 0) {
  dec <- 0
  }
  # Round number to decimal
  out <- format(round(number, dec), nsmall = dec, scientific = FALSE)
  # Remove leading zero if required
  if (out < 1 && lead_zero == FALSE) {
  out <- sub("0.", ".", out)
  }
  return(out)
}
cor_table <- function(data, method = c("pearson", "spearman")) {
  # Compute correlation matrix
  pvalues <- data %>%
  cor_pmat(method = method[1]) %>%
  rowwise() %>%
  mutate(across(!1, formp))
  coefs <- data %>%
  cor_mat(method = method[1]) %>%
  rowwise() %>%
  mutate(across(!1, ~ forma(.x, 2)))
  for (row in seq(2, nrow(coefs))) {
  for (col in seq(2, ncol(coefs) - 1)) {
    c <- coefs[row, col]
    p <- pvalues[row, col]
    coefs[row, col] <- paste0(c, " (", p, ")")
  }
  }
  coefs <- coefs %>%
  pull_lower_triangle() %>%
  slice(-1) %>%
  select(-last_col()) %>%
  rename(variable = 1)
  return(coefs)
}
theme_cs_talk <- function(font = "Nunito", lab_size = 16, label_size = 14,
  dark = "#465263", light = "#849AB9", solid_facet = TRUE) {
  if (solid_facet) {
  facet_fill <- dark
  facet_text <- light
  } else if (!solid_facet) {
  facet_fill <- "transparent"
  facet_text <- dark
  }
  theme_bw(base_size = 16) %+replace%
  theme(
  # Rectangle elements
  plot.background = element_rect(fill = "transparent",
    color = NA_character_),
  panel.background = element_rect(fill = "transparent"),
  legend.background = element_rect(fill = "transparent", color = NA),
  strip.background = element_rect(color = facet_fill,
    fill = facet_fill, linewidth = 1),
  panel.border = element_rect(color = dark, fill = NA, linewidth = 1),
  legend.key = element_rect(fill = "transparent", color = NA_character_),
  # Text elements
  plot.title = element_text(family = font, size = lab_size,
    face = "bold", hjust = 0, vjust = 2, color = dark),
  plot.subtitle = element_text(family = font,
    size = lab_size - 2, color = dark),
  plot.caption = element_text(family = font, size = lab_size,
    hjust = 1, color = dark),
  axis.title = element_text(family = font, size = lab_size,
    color = dark),
  axis.text = element_text(family = font, size = label_size,
    color = dark),
  axis.text.x = element_text(margin = margin(5, b = 10),
    color = dark),
  legend.title = element_text(family = font, size = lab_size,
    color = dark, hjust = 0),
  legend.text = element_text(family = font, size = label_size,
    color = dark),
  strip.text = element_text(family = font, size = label_size,
    color = facet_text, margin = margin(4, 4, 4, 4)),
  # Line elements
  axis.ticks = element_line(color = dark, linewidth = 0.5),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank()
  )
}
theme_cs_apa <- function(font = "Calibri", lab_size = 16, label_size = 14,
  dark = "#000000", light = "#ffffff") {
  theme_bw(base_size = 16) %+replace%
  theme(
  # Rectangle elements
  plot.background = element_blank(),
  panel.background = element_rect(color = "transparent", fill = "transparent"),
  legend.background = element_rect(fill = "transparent", color = dark, linewidth = 0.5),
  legend.box.margin = margin(0, 1, 0, 0, "cm"),
  strip.background = element_rect(color = "transparent",
    fill = light, linewidth = 1),
  legend.key = element_rect(fill = "transparent", color = NA_character_),
  # Text elements
  plot.title = element_text(family = font, size = lab_size,
    face = "bold", hjust = 0, vjust = 2, color = dark),
  plot.subtitle = element_text(family = font,
    size = lab_size - 2, color = dark),
  plot.margin = margin(1, 0.5, 1, 0.5, "cm"),
  plot.caption = element_text(family = font, size = lab_size,
    hjust = 1, color = dark),
  axis.title = element_text(family = font, size = lab_size,
    color = dark, face = "bold"),
  axis.text = element_text(family = font, size = label_size,
    color = dark),
  axis.text.x = element_text(margin = margin(5, b = 10),
    color = dark),
  legend.title = element_text(family = font, size = lab_size,
    color = dark, hjust = 0, , face = "bold"),
  legend.text = element_text(family = font, size = label_size,
    color = dark),
  strip.text = element_text(family = font, size = lab_size,
    color = dark, face = "bold"),
  # Line elements
  axis.ticks = element_blank(),
  axis.line = element_line(color = dark, linewidth = 0.5),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.border = element_rect(fill = "transparent", color = "white"),
  legend.spacing.y = unit(0.4, "cm"),
  legend.key.height = unit(0.5, "cm"),
  legend.key.width = unit(0.5, "cm")
  )
}
```

### Sample Characteristics
We collected data from a total of N = 414 participants. Following our pre-registered exclusion criteria, we excluded 1 participant who did not give informed consent, 0 who gave the same response in all of the 36 test trials, and 7 who rated their own data to be unfit for analysis. We further had to exclude 20 participants due to a programming error. This resulted in a sample of N = `r nrow(dems)` participants (`r nrow(filter(dems, gender == "female"))` female, `r nrow(filter(dems, gender == "male"))` male, `r nrow(filter(dems, gender == "other"))` other, `r nrow(filter(dems, gender %in% c("not specified","")))` not specified; average age M = `r round(mean(dems$age, na.rm = TRUE), 1)` years, SD = `r round(sd(dems$age, na.rm = TRUE), 1)`, ranging from `r min(dems$age, na.rm = TRUE)` to `r max(dems$age, na.rm = TRUE)`). Participants were recruited via the online platform Prolific (www.prolific.co) and received monetary compensation of 3.00 GBP for completing the 20-minute study. An additional 88 people started the experiment on prolific but either returned their submission, timed-out, or only partially completed the experiment due to technical issues.

On average, participants reported to be rather left leaning (M = `r round(mean(dems$pol_orientation, na.rm = TRUE), 1)`, SD = `r round(sd(dems$pol_orientation, na.rm = TRUE), 1)` on a scale from 1 = left to 10 = right) and rather interested in politics (M = `r round(mean(dems$pol_interest), 1)`, SD = `r round(sd(dems$pol_interest), 1)`, on a scale ranging from 1 = not at all to 10 = very strongly).

### Manipulation check
```{r manipulation check, message = FALSE}
check <- d_long %>%
  select(subject_id, reason_type, sufficiency) %>%
  group_by(subject_id, reason_type) %>%
  summarize(.groups = "drop", mn = mean(sufficiency, na.rm = TRUE))

# Descriptives
check_desc <- check %>%
  group_by(reason_type) %>%
  get_summary_stats(mn, type = "mean_sd") %>%
  rowwise() %>%
  mutate(across(c(mean, sd), forma))

# One-sided paired t-test
check_t <- check %>%
  t_test(
  mn ~ reason_type,
  paired = TRUE,
  alternative = "greater",
  ref.group = "sufficient") %>%
  mutate(p = formp(p), statistic = forma(statistic))

# Cohens dz
check_dz <- check %>%
  cohens_d(mn ~ reason_type, paired = TRUE, ref.group = "sufficient") %>%
  pull(effsize) %>%
  forma()

# Print t-test
check_report_plot <- paste0("t(", check_t$df, ") = ", check_t$statistic,
  ",\n ", check_t$p, ",\n dz = ", check_dz)
check_report_text <- paste0("t(", check_t$df, ") = ", check_t$statistic,
  ", ", check_t$p, ", d~z~ = ", check_dz)

# Plot results
check_plot <- check %>%
  ggplot(., aes(x = mn, fill = reason_type, color = reason_type)) +
  labs(x = "Mean sufficiency rating", y = "Count",
      fill = "Reason type", color = "Reason type") +
  scale_x_continuous(limits = c(1, 5), oob = scales::oob_keep) +
  geom_histogram(position = "identity", alpha = .7, bins = 20) +
  scale_fill_manual(values = c("#849AB9", "#465263")) +
  scale_color_manual(values = c("#849AB9", "#465263")) +
  geom_label(aes(x = 4.3, y = 68, label = check_report_plot),
    fill = "white", show.legend = FALSE,
    label.padding = unit(0.5, "lines"), label.size = 0.5) +
  theme_cs_talk()
check_plot
```

We included a manipulation check for reason type. The sufficient reasons are supposed to sufficiently explain the behaviors, whereas the control reasons are supposed to insufficiently explain the behavior (or not explain the behavior at all). We thus asked participants at the end of the study to rate the sufficiency of each reason for the respective behavior and expected the sufficient reasons to score higher than the control reasons. To test this, we conducted a paired t-test. On average, participants gave significantly higher sufficiency ratings in the sufficient condition (M = `r check_desc$mean[2]`, SD = `r check_desc$sd[2]`) than in the control condition (M = `r check_desc$mean[1]`, SD = `r check_desc$sd[1]`), `r check_report_text`. We infer from this, that our manipulation of reason type worked.

### Preregistered analysis {.tabset}
```{r er analysis, message = FALSE}
# Prepare error rate data
er <- d_long %>%
  select(subject_id, probe_type, reason_type, is_correct, stimulus_set) %>%
  group_by(probe_type, reason_type, stimulus_set, subject_id) %>%
  summarize(.groups = "drop_last",
    errors = sum(is_correct == 0),
    n_trials = n()) %>%
  mutate(er = errors / n_trials, .keep = "unused") %>%
  # Find extreme outliers
  mutate(is_extreme = is_extreme(er)) %>%
  ungroup() %T>%
  # Count participants that have extreme outliers
  assign(x = "er_ex_n", envir = .GlobalEnv, value = n_distinct(
    select(filter(., is_extreme == TRUE), subject_id)))

# Create data frame where these rows are excluded
er_ex <- filter(er, is_extreme == FALSE)

# Descriptives
er_3f_desc <- er_ex %>%
  select(stimulus_set, reason_type, probe_type, er) %>%
  group_by(stimulus_set, reason_type, probe_type) %>%
  get_summary_stats(er, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run ANOVA
er_3f_mod <- er_ex %>%
  anova_test(dv = er, wid = subject_id, effect.size = "pes",
    within = c(probe_type, reason_type), between = stimulus_set) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))

# Run post-hoc tests
er_3f_post <- er_ex %>%
  group_by(stimulus_set) %>%
  anova_test(dv = er, wid = subject_id, effect.size = "pes",
    within = c(probe_type, reason_type)) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))
```

We calculated false recognition rates by dividing the number of erroneous responses by six (the number of trials per condition).

#### Outlier detection
```{r er outlier, warning = FALSE, message = FALSE}
er_outlier <- er_ex %>%
  ggplot(., aes(reason_type, er, color = probe_type)) +
  geom_boxplot() +
  labs(x = "Reason type", y = "False recognition rate",
    color = "Probe type") +
  scale_color_manual(values = c("#849AB9", "#465263")) +
  geom_point(
    # Replace all non-outlier values by NA
    data = mutate(er, er = replace(er, is_extreme == FALSE, NA)),
    position = position_dodge(width = 0.75), shape = 4,
    size = 4, show.legend = FALSE) +
  theme_cs_talk()
er_outlier
```

We looked for extreme outliers in each cell of the design. We defined them as values above Q3 + 3 * IQR or below Q1 - 3 * IQR. We found and excluded `r er_ex_n` participants whose values were extreme outliers.

#### QQ-Plot
```{r er checking normality, message = FALSE}
er_qq <- er_ex %>%
  ggplot(., aes(sample = er)) +
  labs(x = "Theoretical quantiles", y = "Data quantiles") +
  stat_qq(color = "#465263") +
  stat_qq_line(color = "#465263") +
  facet_grid(probe_type ~ reason_type, labeller = "label_value") +
  theme_cs_talk()
er_qq
```

Upon visual inspection the distributions of error rates in the different conditions did not seem severely non-normal. We therefore applied no further transformations before conducting our analysis.

#### ANOVA
```{r er ANOVA}
knitr::kable(er_3f_mod, format = "markdown")
```

We conducted a three-way repeated-measures ANOVA to evaluate the effects of probe type, reason type, and stimulus set on the mean response latencies. The main effect for probe type was significant at the pre-registered alpha boundary of \alpha = .041, F(`r er_3f_mod$DFn[2]`, `r er_3f_mod$DFd[2]`) = `r er_3f_mod$F[2]`, `r formp(er_3f_mod$p[2])`, $\eta_{p}^{2}$ = `r er_3f_mod$pes[2]`. This indicates that the implied labels were spontaneously activated while participants read the statements and associated with the actors faces. There was no significant interaction between probe type and reason type, F(`r er_3f_mod$DFn[6]`, `r er_3f_mod$DFd[6]`) = `r er_3f_mod$F[6]`, `r formp(er_3f_mod$p[6])`, $\eta_{p}^{2}$ = `r er_3f_mod$pes[6]`. This suggests that no discounting occured when participants were presented with the sufficient compared to the control reasons.

However, there were unexpected effects involving the stimulus set. First, there was a small but significant main effect of stimulus set, F(`r er_3f_mod$DFn[1]`, `r er_3f_mod$DFd[1]`) = `r er_3f_mod$F[1]`, `r formp(er_3f_mod$p[1])`, $\eta_{p}^{2}$ = `r er_3f_mod$pes[1]`, indicating higher overall error rates in stimulus set B. Second, there was a significant interaction between stimulus set and probe type, F(`r er_3f_mod$DFn[4]`, `r er_3f_mod$DFd[4]`) = `r er_3f_mod$F[4]`, `r formp(er_3f_mod$p[4])`, $\eta_{p}^{2}$ = `r er_3f_mod$pes[4]`, with larger inference effects in stimulus set B. Lastly, there was a significant three-way interaction, F(`r er_3f_mod$DFn[7]`, `r er_3f_mod$DFd[7]`) = `r er_3f_mod$F[7]`, `r formp(er_3f_mod$p[7])`, $\eta_{p}^{2}$ = `r er_3f_mod$pes[7]`, indicating a larger discounting effect in stimulus set B.

#### Descriptives
```{r er descriptives}
knitr::kable(er_3f_desc, format = "markdown")
```

#### Lineplot
```{r er plotting results, message = FALSE}
er_lineplot <- er_3f_desc %>%
  ggplot(., aes(reason_type, mean, color = probe_type, group = probe_type)) +
  facet_wrap(. ~ stimulus_set, labeller = "label_value") +
  labs(x = "Reason type", y = "False recognition rate",
    color = "Probe type") +
  scale_color_manual(values = c("#849AB9", "#465263")) +
  geom_line() +
  geom_point(size = 3) +
  geom_linerange(aes(ymin = ci95_low, ymax = ci95_upp)) +
  theme_cs_talk()
er_lineplot
```

#### Post-hoc tests
```{r er post-hoc tests}
knitr::kable(er_3f_post, format = "markdown")
```

### Comparison between studies
```{r comparison studies, message = FALSE, fig.width = 10, warning = FALSE}
load(here::here("Processed data/desc_SII2b.RData"))
load(here::here("Processed data/desc_SII2.RData"))
desc_SII3 <- er_ex %>%
  select(reason_type, probe_type, er) %>%
  group_by(reason_type, probe_type) %>%
  get_summary_stats(er, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n),
    experiment = "Exp. 5",
    ancillary_statement = recode(reason_type, "sufficient" = "Reason", "control" = "Control"),
    probe_type = recode(probe_type, "implied" = "Implied", "implied other" = "Implied-Other"))
desc_SII2b <- desc_SII2b %>%
  mutate(
    ancillary_statement = recode(reason_type, "sufficient" = "Reason", "control" = "Control"),
    probe_type = recode(probe_type, "implied" = "Implied", "implied other" = "Implied-Other"))
desc_SII2 <- desc_SII2 %>%
  mutate(
    ancillary_statement = recode(reason_type, "sufficient" = "Reason", "control" = "Control"),
    probe_type = recode(probe_type, "implied" = "Implied", "implied other" = "Implied-Other"))

p1 <- desc_SII2b %>%
  ggplot(., aes(x = ancillary_statement, y = mean, fill = probe_type)) +
  facet_wrap(. ~ experiment, labeller = "label_value") +
  labs(x = "", y = "Mean Rating",
    fill = "Probe Type") +
  scale_fill_manual(values = c("#c4c4c4", "#ffffff")) +
  scale_y_continuous(expand = c(0, 0)) +
  coord_cartesian(ylim = c(0, 5)) +
  geom_bar(stat = "identity", position = position_dodge(0.7),
    color = "#000000", width = 0.6) +
  geom_errorbar(aes(ymin = ci95_low, ymax = ci95_upp),
    position = position_dodge(0.7), width = 0.1) +
  theme_cs_apa() +
  theme(legend.position = "none", panel.border = element_blank())

p2 <- desc_SII2 %>%
  ggplot(., aes(x = ancillary_statement, y = mean, fill = probe_type)) +
  facet_wrap(. ~ experiment, labeller = "label_value") +
  labs(x = "Ancillary Statement", y = "Mean Response Latency in ms",
    fill = "Probe Type") +
  scale_fill_manual(values = c("#c4c4c4", "#ffffff")) +
  scale_y_continuous(expand = c(0, 0)) +
  coord_cartesian(ylim = c(600, 1040)) +
  geom_bar(stat = "identity", position = position_dodge(0.7),
    color = "#000000", width = 0.6) +
  geom_errorbar(aes(ymin = ci95_low, ymax = ci95_upp),
    position = position_dodge(0.7), width = 0.1) +
  theme_cs_apa() +
  theme(legend.position = "none", panel.border = element_blank())

p3 <- desc_SII3 %>%
  ggplot(., aes(x = ancillary_statement, y = mean, fill = probe_type)) +
  facet_wrap(. ~ experiment, labeller = "label_value") +
  labs(x = "", y = "False Recognition Rate",
    fill = "Probe Type") +
  scale_fill_manual(values = c("#c4c4c4", "#ffffff")) +
  scale_y_continuous(expand = c(0, 0)) +
  coord_cartesian(ylim = c(0, 0.7)) +
  geom_bar(stat = "identity", position = position_dodge(0.7),
    color = "#000000", width = 0.6) +
  geom_errorbar(aes(ymin = ci95_low, ymax = ci95_upp),
    position = position_dodge(width = 0.7), width = 0.1) +
  theme_cs_apa() +
  theme(panel.border = element_blank()) +
  guides(fill = guide_legend(byrow = TRUE))

p <- ggarrange(p1, p2, p3, ncol = 3, nrow = 1,
  legend.grob = get_legend(p3), legend = "right")
p
```

### Exploratory multilevel analysis {.tabset}
```{r moderation analyses, message = FALSE}
d_mlm <- d_long %>%
  select(
    subject_id, item_id, probe_type, reason_type, is_correct,
    sufficiency, gender, age, pol_orientation, pol_interest) %>%
  mutate(.keep = "unused",
    is_error = abs(1 - is_correct),
    gender = ifelse(gender %in% c("other", "not specified"), NA, gender),
    # Grand mean center level 2 predictors
    age = age - mean(age),
    pol_orientation = pol_orientation - mean(pol_orientation),
    pol_interest = pol_interest - mean(pol_interest),
    probe_type = relevel(probe_type, ref = "implied other")
  ) %>%
  group_by(subject_id) %>%
  mutate(
    sufficiency = sufficiency - mean(sufficiency),
    response = factor(ifelse(
      is_error == TRUE,
      "false recognitions",
      "correct rejections"))) %>%
  mutate(response = factor(response, levels = rev(levels(response)))) %>%
  ungroup()
```

We performed an exploratory multilevel analysis to investigate whether the ratings regarding the sufficiency of the reasons could explain the strength of the SII-effect.

```{r models}
mlm1 <- lme4::glmer(is_error ~ probe_type * reason_type +
  (1 | subject_id) + (1 | item_id),
  data = d_mlm,
  family = binomial(link = "logit"),
  control = glmerControl(optimizer = "bobyqa"))
mlm2 <- lme4::glmer(is_error ~ probe_type * sufficiency +
  (1 | subject_id) + (1 | item_id),
  data = d_mlm,
  family = binomial(link = "logit"),
  control = glmerControl(optimizer = "bobyqa"))
```

We ran two models. Each model had a random effect for participant and item. In Model I we predicted the binary response variable (correct rejection versus false recognition) by probe type and reason type. Only probe type was significant. In Model II we used sufficiency rather than reason type as a predictor. There was a significant effect of probe type, with the probability of a false recognition being higher for implied compared to implied-other probes. There was a marginally significant effect of sufficiency, with higher sufficiency ratings predicting a higher probability of a false recognition. Lastly, there was a significant interaction with an increase of sufficiency predicting a lower probability of a false recognition for implied probes.

#### Model I
```{r multilevel model 1, echo = FALSE}
sjPlot::tab_model(mlm1)
```

#### Model II
```{r multilevel model 2, echo = FALSE}
sjPlot::tab_model(mlm2)
```

#### Visualization sufficiency
```{r multilevel visualization sufficiency, message = FALSE, warning = FALSE, fig.width = 14}
mlm_sufficiency <- d_mlm %>%
  ggplot(., aes(x = sufficiency, y = is_error)) +
  facet_grid(~ probe_type, labeller = "label_value") +
  labs(
    y = "Probability of false recognition",
    x = "Sufficiency", color = "Response") +
  stat_smooth(
    method = "glm", size = 0.5, se = TRUE, level = 0.95,
    color = "#465263", fill = "#849AB9", alpha = 0.5,
    method.args = list(family = binomial)) +
  stat_slab(aes(y = is_error,
    side = ifelse(is_error == 1, "bottom", "top"),
    color = response), fill = "#E0E8ED", alpha = 1,
    slab_type = "pdf", scale = 0.25, size = 0.5) +
  scale_color_viridis_d(option = "mako", begin = 0.4, end = 0.85) +
  theme_cs_talk()
mlm_sufficiency
```

```{r save plots, message = FALSE, eval = FALSE}
ggexport(check_plot, width = 6, height = 5,
  filename = here::here("Analysis/check.pdf"))
ggexport(er_outlier, width = 7, height = 5,
  filename = here("Analysis/er-outlier.pdf"))
ggexport(er_qq, width = 7, height = 7,
  filename = here("Analysis/er-qq.pdf"))
ggexport(er_lineplot, width = 8, height = 5,
  filename = here::here("Analysis/er-lineplot.pdf"))
ggexport(mlm_sufficiency, width = 8, height = 5,
  filename = here::here("Analysis/mlm-sufficiency.pdf"))
ggexport(p, width = 13, height = 5,
  filename = here::here("Analysis/exp-345-barplot.pdf"))
```